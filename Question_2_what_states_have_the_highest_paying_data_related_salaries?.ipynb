{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a089cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "salaries_df = pd.DataFrame(pd.read_excel(\"salary_data_states_corrected.xlsx\"))\n",
    "\n",
    "#Lets see what kind of information this dataframe holds:\n",
    "\n",
    "salaries_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040fd749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see, we have a \"JOB_TITLE_SUBGROUP\" category that we can use to determine if the jobs are related to data.\n",
    "\n",
    "salaries_df[\"JOB_TITLE_SUBGROUP\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c694609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indeed, we have two categories called \"data analyst\" and \"data scientist\" that we can use.\n",
    "#Lets create a seperate dataframe so that we can work on those data jobs easily.\n",
    "\n",
    "data_salaries_df = salaries_df.loc[salaries_df['JOB_TITLE_SUBGROUP'].isin([\"data analyst\", \"data scientist\"])]\n",
    "\n",
    "#Lets also drop rows that have missing state or paid_wage information, since we can't use them on our calculations\n",
    "\n",
    "data_salaries_df = data_salaries_df.dropna(subset=['WORK_STATE', 'PAID_WAGE_PER_YEAR'])\n",
    "\n",
    "#We actually don't need to have this here since there are no NaN values associates with these parameters, but it is\n",
    "#Nice to keep this part just incase if we want to use this code with different data with same structure in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f029d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets group the salary information by taking average yearly paid wage into account and sort them in descending order\n",
    "\n",
    "sorted_sal_df = data_salaries_df.groupby('WORK_STATE').mean().sort_values(by=\"PAID_WAGE_PER_YEAR\", ascending=[False])\n",
    "sorted_sal_df = sorted_sal_df.reset_index() #We need to do this to create a plot later\n",
    "sorted_sal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As expected, California pays the most when it comes to data related jobs. However, it is surprizing to note that\n",
    "#Utah is also close to the top, could this be related to massive NSA data center located around Bluffdale? Probably.\n",
    "\n",
    "#Lets use this information to create a plot so that we can visualy see the difference\n",
    "#I will use the top 7 states to make the plot comprehensible, this can be changes by changing the variable below\n",
    "\n",
    "state_count = 7\n",
    "sorted_sal_df.head(state_count).plot(x ='WORK_STATE', y='PAID_WAGE_PER_YEAR', kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, lets explore the differences between different job subtypes, namely \"data analyst\" and \"data scientist\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
